<?xml version="1.0" encoding="iso-8859-1"?>
<ipm_job_profile>
<calltable nsections="1" >
<section module="MPI" nentries="69" >
<entry name="MPI_Init" />
<entry name="MPI_Init_thread" />
<entry name="MPI_Finalize" />
<entry name="MPI_Comm_rank" />
<entry name="MPI_Comm_size" />
<entry name="MPI_Send" />
<entry name="MPI_Ssend" />
<entry name="MPI_Rsend" />
<entry name="MPI_Bsend" />
<entry name="MPI_Isend" />
<entry name="MPI_Issend" />
<entry name="MPI_Irsend" />
<entry name="MPI_Ibsend" />
<entry name="MPI_Recv" />
<entry name="MPI_Irecv" />
<entry name="MPI_Sendrecv" />
<entry name="MPI_Sendrecv_replace" />
<entry name="MPI_Wait" />
<entry name="MPI_Waitany" />
<entry name="MPI_Waitall" />
<entry name="MPI_Waitsome" />
<entry name="MPI_Probe" />
<entry name="MPI_Iprobe" />
<entry name="MPI_Send_init" />
<entry name="MPI_Ssend_init" />
<entry name="MPI_Rsend_init" />
<entry name="MPI_Bsend_init" />
<entry name="MPI_Recv_init" />
<entry name="MPI_Buffer_attach" />
<entry name="MPI_Buffer_detach" />
<entry name="MPI_Test" />
<entry name="MPI_Testany" />
<entry name="MPI_Testall" />
<entry name="MPI_Testsome" />
<entry name="MPI_Start" />
<entry name="MPI_Startall" />
<entry name="MPI_Bcast" />
<entry name="MPI_Reduce" />
<entry name="MPI_Reduce_scatter" />
<entry name="MPI_Barrier" />
<entry name="MPI_Gather" />
<entry name="MPI_Gatherv" />
<entry name="MPI_Scatter" />
<entry name="MPI_Scatterv" />
<entry name="MPI_Scan" />
<entry name="MPI_Allgather" />
<entry name="MPI_Allgatherv" />
<entry name="MPI_Allreduce" />
<entry name="MPI_Alltoall" />
<entry name="MPI_Alltoallv" />
<entry name="MPI_Comm_group" />
<entry name="MPI_Comm_compare" />
<entry name="MPI_Comm_dup" />
<entry name="MPI_Comm_create" />
<entry name="MPI_Comm_split" />
<entry name="MPI_Comm_free" />
<entry name="MPI_Ibcast" />
<entry name="MPI_Ireduce" />
<entry name="MPI_Ireduce_scatter" />
<entry name="MPI_Igather" />
<entry name="MPI_Igatherv" />
<entry name="MPI_Iscatter" />
<entry name="MPI_Iscatterv" />
<entry name="MPI_Iscan" />
<entry name="MPI_Iallgather" />
<entry name="MPI_Iallgatherv" />
<entry name="MPI_Iallreduce" />
<entry name="MPI_Ialltoall" />
<entry name="MPI_Ialltoallv" />
</section>
</calltable>
<task ipm_version="2.0.6" cookie="nocookie" mpi_rank="0" mpi_size="2" stamp_init="1699776016.910127" stamp_final="1699776033.547146" username="pp23s78" allocationname="unknown" flags="0" pid="944843" >
<job nhosts="1" ntasks="2" start="1699776016" final="1699776033" cookie="nocookie" code="unknown" >4979683</job>
<host mach_name="x86_64" mach_info="x86_64_Linux" >apollo37</host>
<perf wtime="1.66370e+01" utime="5.24364e+01" stime="2.85242e-01" mtime="1.55074e-01" gflop="0.00000e+00" gbyte="4.18179e-01" omp_num_threads="1"></perf>
<modules nmod="2">
<module name="MPI" time="1.55074e-01" ></module>
<module name="PAPI" time="0.0" ncpu="6" nnodes="2" totalcpus="12" threads="1" cores="6"  vendor="1" vendor_string="GenuineIntel" model="44" model_string="Intel(R) Xeon(R) CPU           X5670  @ 2.93GHz" revision="2.000000" min_mhz="1600" max_mhz="2933" domain="15"></module>
</modules>
<switch bytes_tx="0.00000e+00" bytes_rx="0.00000e+00" ></switch>
<cmdline realpath="/home/pp23/pp23s78/ParallelProgramming/hw/hw2/experiment_version/hw2b" md5sum="8fc1af4f6c7fe77f2b562b560000e77f42" >hw2b out.png 10000 -0.5506211524210792 -0.5506132348972915 0.6273469513234796 0.6273427528329604 7680 4320 </cmdline>
<regions n="1" >
<region label="ipm_noregion" nexits="1" wtime="1.65769e+01" utime="5.24338e+01" stime="2.82818e-01" mtime="1.55074e-01" id="0">
<modules nmod="2">
<module name="MPI" time="1.55074e-01" ></module>
<module name="PAPI" time="0.0" ncpu="6" nnodes="2" totalcpus="12" threads="1" cores="6"  vendor="1" vendor_string="GenuineIntel" model="44" model_string="Intel(R) Xeon(R) CPU           X5670  @ 2.93GHz" revision="2.000000" min_mhz="1600" max_mhz="2933" domain="15"></module>
</modules>
<hpm api="PAPI" ncounter="0" eventset="0" gflop="0.00000e+00" >
</hpm>
<func name="MPI_Init" count="1" bytes="0.0000e+00" > 0.0000e+00 </func>
<func name="MPI_Finalize" count="1" bytes="0.0000e+00" > 0.0000e+00 </func>
<func name="MPI_Comm_rank" count="1" bytes="0.0000e+00" > 2.8610e-06 </func>
<func name="MPI_Comm_size" count="1" bytes="0.0000e+00" > 0.0000e+00 </func>
<func name="MPI_Gatherv" count="1" bytes="5.8720e+07" > 1.5507e-01 </func>
</region>
</regions>
<hash nlog="5" nkey="5" >
<hent key="01000100000000000000000000000000" call="MPI_Comm_size" bytes="0" orank="0" region="0" callsite="0" count="1" tid="0" op="" dtype="" >0.0000e+00 0.0000e+00 0.0000e+00</hent>
<hent key="00C00100000000000000000000000000" call="MPI_Comm_rank" bytes="0" orank="0" region="0" callsite="0" count="1" tid="0" op="" dtype="" >2.8610e-06 2.8610e-06 2.8610e-06</hent>
<hent key="00800100000000000000000000000000" call="MPI_Finalize" bytes="0" orank="0" region="0" callsite="0" count="1" tid="0" op="" dtype="" >0.0000e+00 0.0000e+00 0.0000e+00</hent>
<hent key="00000100000000000000000000000000" call="MPI_Init" bytes="0" orank="0" region="0" callsite="0" count="1" tid="0" op="" dtype="" >0.0000e+00 0.0000e+00 0.0000e+00</hent>
<hent key="0A400100000004000380000000000000" call="MPI_Gatherv" bytes="58720256" orank="0" region="0" callsite="0" count="1" tid="0" op="" dtype="MPI_INT" >1.5507e-01 1.5507e-01 1.5507e-01</hent>
</hash>
<internal rank="0" log_i="1699776033.547146" log_t="1.6998e+09" report_delta="-1.0000e+00" fname="./pp23s78.1699776016.910127.ipm.xml" logrank="0" ></internal>
</task>
<task ipm_version="2.0.6" cookie="nocookie" mpi_rank="1" mpi_size="2" stamp_init="1699776016.910163" stamp_final="1699776029.919479" username="pp23s78" allocationname="unknown" flags="0" pid="944844" >
<job nhosts="1" ntasks="2" start="1699776016" final="1699776029" cookie="nocookie" code="unknown" >4979683</job>
<host mach_name="x86_64" mach_info="x86_64_Linux" >apollo37</host>
<perf wtime="1.30093e+01" utime="4.92573e+01" stime="1.48533e-01" mtime="6.62639e-02" gflop="0.00000e+00" gbyte="4.18179e-01" omp_num_threads="1"></perf>
<modules nmod="2">
<module name="MPI" time="1.55074e-01" ></module>
<module name="PAPI" time="0.0" ncpu="6" nnodes="2" totalcpus="12" threads="1" cores="6"  vendor="1" vendor_string="GenuineIntel" model="44" model_string="Intel(R) Xeon(R) CPU           X5670  @ 2.93GHz" revision="2.000000" min_mhz="1600" max_mhz="2933" domain="15"></module>
</modules>
<switch bytes_tx="0.00000e+00" bytes_rx="0.00000e+00" ></switch>
<cmdline realpath="/home/pp23/pp23s78/ParallelProgramming/hw/hw2/experiment_version/hw2b" md5sum="8fc1af4f127f4c7f8f568f5600004c7f45" >hw2b out.png 10000 -0.5506211524210792 -0.5506132348972915 0.6273469513234796 0.6273427528329604 7680 4320 </cmdline>
<regions n="1" >
<region label="ipm_noregion" nexits="1" wtime="1.29491e+01" utime="4.92548e+01" stime="1.45884e-01" mtime="6.62639e-02" id="0">
<modules nmod="2">
<module name="MPI" time="1.55074e-01" ></module>
<module name="PAPI" time="0.0" ncpu="6" nnodes="2" totalcpus="12" threads="1" cores="6"  vendor="1" vendor_string="GenuineIntel" model="44" model_string="Intel(R) Xeon(R) CPU           X5670  @ 2.93GHz" revision="2.000000" min_mhz="1600" max_mhz="2933" domain="15"></module>
</modules>
<hpm api="PAPI" ncounter="0" eventset="0" gflop="0.00000e+00" >
</hpm>
<func name="MPI_Init" count="1" bytes="0.0000e+00" > 0.0000e+00 </func>
<func name="MPI_Finalize" count="1" bytes="0.0000e+00" > 0.0000e+00 </func>
<func name="MPI_Comm_rank" count="1" bytes="0.0000e+00" > 3.0994e-06 </func>
<func name="MPI_Comm_size" count="1" bytes="0.0000e+00" > 0.0000e+00 </func>
<func name="MPI_Gatherv" count="1" bytes="5.8720e+07" > 6.6261e-02 </func>
</region>
</regions>
<hash nlog="5" nkey="5" >
<hent key="01000100000000000000000000000000" call="MPI_Comm_size" bytes="0" orank="0" region="0" callsite="0" count="1" tid="0" op="" dtype="" >0.0000e+00 0.0000e+00 0.0000e+00</hent>
<hent key="00C00100000000000000000000000000" call="MPI_Comm_rank" bytes="0" orank="0" region="0" callsite="0" count="1" tid="0" op="" dtype="" >3.0994e-06 3.0994e-06 3.0994e-06</hent>
<hent key="00800100000000000000000000000000" call="MPI_Finalize" bytes="0" orank="0" region="0" callsite="0" count="1" tid="0" op="" dtype="" >0.0000e+00 0.0000e+00 0.0000e+00</hent>
<hent key="00000100000000000000000000000000" call="MPI_Init" bytes="0" orank="0" region="0" callsite="0" count="1" tid="0" op="" dtype="" >0.0000e+00 0.0000e+00 0.0000e+00</hent>
<hent key="0A400100000004000380000000000000" call="MPI_Gatherv" bytes="58720256" orank="0" region="0" callsite="0" count="1" tid="0" op="" dtype="MPI_INT" >6.6261e-02 6.6261e-02 6.6261e-02</hent>
</hash>
<internal rank="1" log_i="1699776029.919479" log_t="1.6998e+09" report_delta="-1.0000e+00" fname="./pp23s78.1699776016.910127.ipm.xml" logrank="0" ></internal>
</task>
</ipm_job_profile>
